# -*- coding: utf-8 -*-
"""spotify.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p4bgJsYXU7A-T0sSWmrp51OeHFbSjMPc

# Load Packages
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.neighbors import NearestNeighbors

"""# Data Loading & Overview
- Load the dataset
- Understand structure, data types, and completeness
"""

file = "dataset.csv"
df = pd.read_csv(file)
df.head()

print(len(df))
print(df['track_id'].nunique())

print(df.info())
print(df.describe())
print(df.isna().sum())

### show NA rows in specific column
# df[df['artists'].isna()]
### show NA rows in any column
# df[df.isna().any(axis=1)]

"""# Data Cleaning
- Drop duplicates: df_cleaned
- Handle missing values: df_cleaned
- Split the artists into multiple rows: df_exploded

## Drop duplicates
Based on our findings, the dataset contains 114,000 rows with 89,741 unique track IDs, resulting in 24,259 duplicates â€” a duplication rate of 21.28%, primarily due to the presence of multiple **track_genre** entries and **popularity** per track.

### Process

Step1: Check if there're duplicates
"""

duplicate_track_ids = df['track_id'].duplicated().sum()
total_track_ids = df['track_id'].shape[0]
unique_track_ids = df['track_id'].nunique()
unique_track_ids_showonce = df['track_id'].value_counts().eq(1).sum()

print(f"Number of duplicate track_id entries: {duplicate_track_ids}")
print(f"Total number of track_id entries: {total_track_ids}")
print(f"Number of unique track_id entries: {unique_track_ids}")
print(f"Number of unique track_id entries show once: {unique_track_ids_showonce}")
print(f"Percentage duplicated: {duplicate_track_ids / total_track_ids:.2%}")

### Preview duplicate rows
# df[df['track_id'].duplicated(keep=False)].sort_values('track_id')

"""Step2: Identify duplicated track_ids"""

df_duplicates = df[df['track_id'].duplicated(keep=False)]
df_duplicates.head()

"""Step3: Check which columns differ across the duplicates"""

diff_summary = df_duplicates.groupby('track_id').nunique()

varing_cols = diff_summary.loc[:, (diff_summary > 1).any()]
print("These columns differ across the duplicates:")
print(varying_cols.columns.tolist())

popularity_counts = df.groupby('track_id')['popularity'].nunique()
track_ids_with_popularity_duplicates = popularity_counts[popularity_counts > 1]
rows_with_popularity_duplicates = df[df['track_id'].isin(track_ids_with_popularity_duplicates.index)]

print(f"Number of rows where track_id has different popularity values: {rows_with_popularity_duplicates.shape[0]}")
print(f"Number of affected track_ids: {track_ids_with_popularity_duplicates.shape[0]}")

# rows_with_popularity_duplicates.sort_values('track_id').head(10)

track_genre_counts = df.groupby('track_id')['track_genre'].nunique()
track_ids_with_track_genre_duplicates = track_genre_counts[track_genre_counts > 1]
rows_with_track_genre_duplicates = df[df['track_id'].isin(track_ids_with_track_genre_duplicates.index)]

print(f"Number of rows where track_id has different track_genre values: {rows_with_track_genre_duplicates.shape[0]}")
print(f"Number of affected track_ids: {track_ids_with_track_genre_duplicates.shape[0]}")

# rows_with_track_genre_duplicates.sort_values('track_id').head(10)

"""### Result"""

# columns_to_check = df.columns[1:]
df.drop_duplicates(subset='track_id', inplace=True)
df_cleaned = df

print(len(df_cleaned))
print(df_cleaned['track_id'].nunique())

df_genre = df[~df.duplicated(subset=columns_to_check, keep='first')].reset_index(drop=True)

"""## Handle missing values
Only one column has NA in artists, album_name, track_name, we can directly remove it

### Process
"""

print(df_cleaned.isna().sum())

df_cleaned[df_cleaned.isna().any(axis=1)]

"""### Result"""

df_cleaned.dropna(inplace=True)

print(len(df_cleaned))
print(df_cleaned['track_id'].nunique())

"""## Split the artists into multiple rows"""

df_cleaned['artists'] = df_cleaned['artists'].str.split(';')
df_exploded = df_cleaned.explode('artists').reset_index(drop=True)

print(len(df_exploded))
print(df_exploded['track_id'].nunique())

"""# Exploratory Data Analysis (EDA)

## A. Popularity Distribution
"""

plt.figure(figsize=(12, 8))
sns.histplot(df_cleaned['popularity'], kde=True)
plt.title("Distribution of Track Popularity")

"""## B. Genre Distribution"""

df_genre['track_genre'].nunique()

genre_summary = (
    df_genre.groupby('track_genre')
      .agg(unique_tracks=('track_id', 'nunique'),
           avg_popularity=('popularity', 'mean'))
      .reset_index()
      .sort_values('unique_tracks', ascending=False)
)

genre_summary

top20_by_avg_popularity = genre_summary.sort_values('avg_popularity', ascending=False).head(10)

top20_by_avg_popularity.plot(
    kind='barh',
    x='track_genre',
    y='avg_popularity',
    figsize=(8, 6),
    legend=False
)
plt.title("Top 10 Genres by Avg Popularity")
plt.xlabel("Avg Popularity")
plt.ylabel("Genre")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""## C. Correlation Heatmap"""

feature_cols = ['danceability', 'energy','loudness', 'speechiness','acousticness','instrumentalness','liveness','valence', 'tempo']

plt.figure(figsize=(12, 8))
sns.heatmap(df_cleaned[feature_cols + ['popularity']].corr(), annot=True)

"""# Recommendation System
**Goal: Recommend tracks based on user-input audio preferences**


Use feature_cols = ['danceability', 'energy','loudness', 'speechiness','acousticness','instrumentalness','liveness','valence', 'tempo'] to define the recommendations. Set n_neighbors=5 so that we can have more diverse recommendations

Step1: Feature Normalization
"""

scaler = StandardScaler()
df_cleaned_scaled = df_cleaned.copy()
df_cleaned_scaled[feature_cols] = scaler.fit_transform(df_cleaned[feature_cols])

"""Step2: Get Recommendations"""

# Example: High energy, medium speechiness, low acousticness
user_input_raw = [[0.8, 0.9, -5.0, 0.1, 0.1, 0.0, 0.2, 0.9, 130]]
user_input_scaled = scaler.transform(user_input_raw)

knn = NearestNeighbors(n_neighbors=5).fit(df_cleaned_scaled[feature_cols])
_, indices = knn.kneighbors(user_input_scaled)

# Show recommendations
df_cleaned.iloc[indices[0]][['track_name', 'artists', 'track_genre', 'popularity']]

"""# Genre Classfication
**Goal: Predict genre using audio features**

Step1: Prepare data
"""

X = df_cleaned[feature_cols]
y = df_cleaned['track_genre']
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)

"""Step2: Train Model"""

clf = RandomForestClassifier(class_weight='balanced', random_state=42)
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)
print(classification_report(y_test, y_pred))

report_dict = classification_report(y_test, y_pred, output_dict=True)
df_report = pd.DataFrame(report_dict).transpose()
df_report

"""Step3: Feature Importance"""

importances = pd.Series(clf.feature_importances_, index=feature_cols)
importances.sort_values().plot(kind='barh')
plt.title("Feature Importance in Genre Classification")

"""# Emerging Track & Artist Identification
**Goal: Surface high-potential tracks and rising artists**

Step1: Define Emerging Criteria
"""

df_emerging = df_cleaned[(df_cleaned['popularity'] >= 40) & (df_cleaned['popularity'] <= 70)]
df_emerging['emerging_score'] = (
    df_emerging['danceability'] +
    df_emerging['energy'] +
    df_emerging['valence'] +
    df_emerging['tempo'] / 200 -
    df_emerging['loudness'] / 60
)

"""Step2: Output the top 10 "most promising tracks"
"""

df_emerging.sort_values('emerging_score', ascending=False).head(10)

"""Step3: Output the top 10 "most promising artists"
"""

emerging_artists = df_emerging.groupby('main_artist')['emerging_score'].mean().sort_values(ascending=False).head(10)
emerging_artists.plot(kind='barh')
plt.title("Top Emerging Artists")

"""# Popularity Drivers by Genre
**Goal: What drives popularity across genres?**
"""

coef_table = []

for genre in df_cleaned['track_genre'].unique():
    temp = df_cleaned[df_cleaned['track_genre'] == genre]
    if len(temp) > 30:
        X = temp[feature_cols]
        y = temp['popularity']
        model = LinearRegression().fit(X, y)
        for i, f in enumerate(feature_cols):
            coef_table.append({
                'genre': genre,
                'feature': f,
                'coefficient': model.coef_[i]
            })

coef_df = pd.DataFrame(coef_table)

plt.figure(figsize=(12, 20))
sns.barplot(data=coef_df[coef_df['feature']=='valence'], x='coefficient', y='genre')
plt.title("Impact of Valence on Popularity by Genre")

valence_impact = coef_df[coef_df['feature'] == 'valence'].sort_values('coefficient', ascending=False)
sns.barplot(data=valence_impact.head(10), x='coefficient', y='genre')
plt.title("Impact of Valence on Popularity by Genre")

energy_impact = coef_df[coef_df['feature'] == 'energy'].sort_values('coefficient', ascending=False)
sns.barplot(data=energy_impact.head(10), x='coefficient', y='genre')
plt.title("Impact of energy on Popularity by Genre")

danceability_impact = coef_df[coef_df['feature'] == 'danceability'].sort_values('coefficient', ascending=False)
sns.barplot(data=danceability_impact.head(10), x='coefficient', y='genre')
plt.title("Impact of danceability on Popularity by Genre")